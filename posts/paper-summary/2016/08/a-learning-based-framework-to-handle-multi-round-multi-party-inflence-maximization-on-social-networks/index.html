<!DOCTYPE html>
<html lang="zh">

<head>
            <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">


        <title>[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks</title>

        <link href="//lee-w.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Life Lies in Traveling Full Atom Feed" />
        <!-- Bootstrap Core CSS -->
        <link href="http://lee-w.github.io/theme/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom CSS -->
        <link href="http://lee-w.github.io/theme/css/clean-blog.min.css" rel="stylesheet">

        <!-- Code highlight color scheme -->
            <link href="http://lee-w.github.io/theme/css/code_blocks/darkly.css" rel="stylesheet">

            <!-- CSS specified by the user -->
            <link href="http://lee-w.github.io//static/custom.css" rel="stylesheet">

        <!-- Custom Fonts -->
        <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
        <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/v4-shims.js"></script>
        <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->



        <meta name="description" content="Paper">

        <meta name="author" content="Lee-W">

        <meta name="tags" content="Social Network">
        <meta name="tags" content="Machine Learning">
        <meta name="tags" content="Game Theory">

	                <meta property="og:locale" content="">
		<meta property="og:site_name" content="Life Lies in Traveling">

	<meta property="og:type" content="article">
            <meta property="article:author" content="http://lee-w.github.io/author/lee-w.html">
	<meta property="og:url" content="http://lee-w.github.io/posts/paper-summary/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks">
	<meta property="og:title" content="[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks">
	<meta property="article:published_time" content="2016-08-22 16:53:00+08:00">
            <meta property="og:description" content="Paper">

            <meta property="og:image" content="http://lee-w.github.io//images/cover.jpg">
</head>

<body class="article-a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="http://lee-w.github.io/">Life Lies in Traveling</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                        <li><a href="/archives.html">Archives</a></li>
                        <li><a href="/categories.html">Categories</a></li>
                        <li><a href="/tags.html">Tags</a></li>

                            <li><a href="http://lee-w.github.io/pages/about-me.html">About&nbsp;Me</a></li>
                            <li><a href="http://lee-w.github.io/pages/about-this-blog.html">About This&nbsp;Blog</a></li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
        <header class="intro-header" style="background-image: url('http://lee-w.github.io//images/cover.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>[Paper] A Learning-based Framework to Handle Multi-round Multi-party Influence Maximization on Social Networks</h1>
                        <span class="meta">Posted by
                                <a href="http://lee-w.github.io/author/lee-w.html">Lee-W</a>
                             on 2016/08/22 - 一
                        </span>
                        
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
    <!-- Post Content -->
    <article>
        <p><a href="http://dl.acm.org/citation.cfm?id=2783392">Paper</a></p>
<!--more-->

<h2>1.&nbsp;Introduction</h2>
<ul>
<li>
<p>Problem&nbsp;Description</p>
<ul>
<li>A company intends to select a small set of customers to distribute praises of their trial products to a larger&nbsp;group</li>
</ul>
</li>
<li>
<p>Influence&nbsp;maximization</p>
<ul>
<li>Goal: Identify a small subset of seed nodes that have the best chance to influence the most number of&nbsp;nodes</li>
<li>Competitive Influence Maximization (<span class="caps">CIM</span>)</li>
</ul>
</li>
<li>
<p>Assumption</p>
<ul>
<li>Influence is exclusive (Once a node is influenced by one party, it will not be influenced&nbsp;again)      </li>
<li>Each round all parties choose one node and then the influence propagates before the next round&nbsp;starts</li>
</ul>
</li>
<li>
<p><span class="caps">STORM</span> (STrategy-Oriented Reinforcement-Learning based influence Maximization)&nbsp;performs</p>
<ul>
<li>Data Generation<ul>
<li>the data, which is the experience generated through simulation by applying the current model, will become the feedbacks to refine the model for better&nbsp;performance </li>
</ul>
</li>
<li>Model&nbsp;Learning </li>
</ul>
</li>
</ul>
<h3>Difference with&nbsp;Others</h3>
<ol>
<li>Known strategy -&gt; Both know and unknown<ul>
<li>Known or Unknown but available to compete -&gt; Train a model to learn&nbsp;strategy</li>
<li>Unknown -&gt; Game-theoretical solution to seek the Nash&nbsp;equilibrium     </li>
</ul>
</li>
<li>Single-roung -&gt;&nbsp;Multi-round</li>
<li>Model driven -&gt; learning-based,&nbsp;data-drivern</li>
<li>Not considering different network topology -&gt; General to adapt both opponent&#8217;s strategy and environment setting (e.g. underlying network&nbsp;topology)</li>
</ol>
<h2>2. Problem&nbsp;Statment</h2>
<h3>Def 1: Competive Linear Threshold (<span class="caps">CLT</span>)</h3>
<ul>
<li><span class="caps">CLT</span> model is a multi-party diffusion&nbsp;model</li>
<li>The party who has the highest influence occupied the&nbsp;node</li>
</ul>
<h3>Def 2: Multi-Round Competitive Influence Maximization (<span class="caps">MRCIM</span>)</h3>
<ul>
<li>Max its overall relative&nbsp;influence</li>
</ul>
<h2>4.&nbsp;Methodology</h2>
<ul>
<li><span class="caps">NP</span>-hardness of <span class="caps">MRCIM</span> -&gt; looks for approxmiate&nbsp;solution</li>
<li>Max the inflence for each round does not guarantee overall max<ul>
<li>Due to the fact that each round are not&nbsp;independent</li>
</ul>
</li>
</ul>
<h3>4.1 Preliminary: Reinforcement&nbsp;Learning</h3>
<ul>
<li>Learn a policy <span class="math">\(\pi(s)\)</span> to determine which action to take state s&nbsp;(environment)</li>
<li>How to estimated <span class="math">\(\pi\)</span>?<ul>
<li>Expected Accmulated Reward of a state (V function)<ul>
<li><span class="math">\( V^\pi(s) =&nbsp;E_\pi\{R_t|S_t=s\}=...\)</span></li>
</ul>
</li>
<li>Expected Accmulated Reward of a state-action pair (Q function)<ul>
<li><span class="math">\( Q^\pi(s, a) = E_\pi\{R_t|S_t=s,&nbsp;a_t=a\}=...\)</span></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The optimal <span class="math">\(\pi\)</span> can be obtained through Q&nbsp;functinon</p>
<p><span class="math">\( \pi = \arg \min_{a\in&nbsp;A}Q(s,a)\)</span></p>
<p>(i.e. For all &#8220;a&#8221; in A, find the &#8220;a&#8221; such that min Q(s,&nbsp;a))</p>
<h3>4.2 Strategy-Oriented&nbsp;Reinforcement-Learning</h3>
<h4>Setup</h4>
<ul>
<li>Env<ul>
<li>Influence propagation&nbsp;process</li>
</ul>
</li>
<li>Reward<ul>
<li>Delay Reward: The difference of activated nodes between parties at the last round<ul>
<li>After the last round, rewards are propagated to the previous states through Q-function&nbsp;updating</li>
<li>Slow but more&nbsp;accurate</li>
</ul>
</li>
</ul>
</li>
<li>Action<ul>
<li><s>Choosing certain node to activate</s><ul>
<li>too&nbsp;many</li>
<li>overfit</li>
</ul>
</li>
<li>Single Party <span class="caps">IM</span> strategies<ul>
<li>Namely, which strategy to choose given the current&nbsp;state</li>
<li>The size can be reduced to strategies&nbsp;choosen</li>
<li>Chosen Strategies<ul>
<li>sub-greedy</li>
<li>degree-first</li>
<li>block</li>
<li>max-weight</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>State<ul>
<li>Represents<ul>
<li>network</li>
<li>environment&nbsp;status</li>
</ul>
</li>
<li><s>record the occupation status of all nodes</s><ul>
<li><span class="math">\(3^{|V|}\)</span>, too&nbsp;many</li>
<li>overfit</li>
</ul>
</li>
<li>Features Designed<ul>
<li>Number of free&nbsp;nodes</li>
<li>Sum of degrees of all&nbsp;nodes</li>
<li>Sum of weight of the edges for which bot h vertices are&nbsp;free</li>
<li>Max degree among all free&nbsp;nodes</li>
<li>Max sum of free out-edge weight of a node among nodes which are the first player&#8217;s&nbsp;neighbors</li>
<li>Second&nbsp;player&#8217;s </li>
<li>Max activated nodes of a node for the first player alter two rounds of influence&nbsp;propagation</li>
<li>Second&nbsp;player&#8217;s</li>
</ul>
</li>
<li>The feautres are quantize into<ul>
<li>low</li>
<li>medium</li>
<li>high</li>
</ul>
</li>
<li>Totally, <span class="math">\(3^9\)</span>&nbsp;states</li>
</ul>
</li>
</ul>
<h4>Data For&nbsp;Training</h4>
<ul>
<li>Propagation model is known (e.g. <span class="caps">LT</span> in the&nbsp;experiments)</li>
<li>Strategies served as actions are&nbsp;predefined</li>
</ul>
<p>In training phase, train the agent aginst a certain strategy and see how it performs on the given network<br>
These data can be used to learn the value&nbsp;functions</p>
<h4>Training Against&nbsp;Opponents</h4>
<ul>
<li>Opponent Strategy<ul>
<li>Known: Simulate the strategy during&nbsp;training</li>
<li>Unknown but availble during training: Same as&nbsp;above</li>
<li>Unknown: More Gerneral Model in&nbsp;4.4</li>
</ul>
</li>
</ul>
<h4>Phase</h4>
<ul>
<li>Phase 1: Training<ul>
<li>The agent update its Q function from the simulation experiences throughout the training&nbsp;rounds</li>
<li>Update <span class="math">\(\pi\)</span> in the&nbsp;meantime</li>
</ul>
</li>
<li>Phase 2: Competition<ul>
<li>The agent would not update&nbsp;Q-table</li>
<li>Generates <span class="math">\(\pi\)</span> according to&nbsp;Q-table</li>
</ul>
</li>
</ul>
<h2>4.3 <span class="caps">STORM</span> with Strategy&nbsp;Known</h2>
<ul>
<li>Training the model compete against the strategy to learn <span class="math">\(\pi\)</span></li>
<li><span class="caps">STORM</span>-Q<ul>
<li>Update Q-function following the concept of Q-learning<ul>
<li>Q-Learning: <span class="math">\(Q(S_t, a_t) = Q(S_t, a_t) + \alpha * (r_{t+1} + \gamma * max_{a}Q(S_{t+1}, a) -Q(S_t,&nbsp;a_t))\)</span></li>
</ul>
</li>
<li><span class="math">\(\epsilon\)</span>-greedy<ul>
<li>Determine strategies on the current policy derived from&nbsp;Q-table.</li>
<li>Explore the new directions to avoid local&nbsp;optimum</li>
</ul>
</li>
<li>Pure&nbsp;Strategy</li>
<li>The most likely strategy is&nbsp;choosen</li>
</ul>
</li>
</ul>
<p>$ Algorithm&nbsp;$</p>
<h2>4.4 <span class="caps">STORM</span> with Strategy&nbsp;Unknown</h2>
<h3>Unknown but available to&nbsp;train</h3>
<ul>
<li>The differece between the known case is that experience cannot be obtained through&nbsp;simulation</li>
<li>Train against unknown opponent&#8217;s strategy during competition<ul>
<li>It&#8217;s feasible because <span class="caps">STORM</span>-Q only needs to know the seed-selection outcoms of the opponent to update the Q-table, not exact strategy it&nbsp;takes</li>
</ul>
</li>
</ul>
<h3>Unknown</h3>
<ul>
<li>Goal: Create a general model to compete a variety of rational&nbsp;strategies</li>
<li>Assumption: The oppoent is rational (Wants to max influence and knows its oppoent wants&nbsp;so)</li>
<li><span class="caps">STORM</span>-<span class="caps">QQ</span><ul>
<li>Two <span class="caps">STROM</span>-Q compete and update Q-tabale at the same&nbsp;time</li>
<li>Using current Q-table during training&nbsp;phase</li>
<li>Pure Strategy<ul>
<li>Does Not guarantee that equilibrium exists in <span class="caps">MRCIM</span></li>
</ul>
</li>
</ul>
</li>
<li>
<p><span class="caps">STORM</span>-<span class="caps">MM</span></p>
<ul>
<li>Mix Strategy (Samples an action from the distribution of actions in each&nbsp;state)</li>
<li>In two-player zero-sum game<ul>
<li>Nash equilibrium is graranteed to exist with miexed&nbsp;strategies</li>
<li>Use <span class="caps">MINMAX</span> theorem to find the&nbsp;equilibrium</li>
</ul>
</li>
<li><span class="math">\(Q(s, a, o)\)</span>: The reward of first party when using strategy <span class="math">\(a\)</span> against oppoent&#8217;s strategy <span class="math">\(o\)</span> in state <span class="math">\(s\)</span></li>
<li><span class="math">\(Q_{t+1}(s_t, a_t, o_t) = (1-\alpha)Q_t(s_t, a_t, o_t)+\alpha[r_{t+1}+\gamma&nbsp;V(s_{t+1})]\)</span></li>
<li>Operations&nbsp;Research</li>
</ul>
</li>
<li>
<p>The differece between <span class="caps">STROM</span>-<span class="caps">QQ</span> and <span class="caps">STORM</span>-<span class="caps">MM</span></p>
</li>
</ul>
<table>
<thead>
<tr>
<th><span class="caps">STROM</span>-<span class="caps">QQ</span></th>
<th><span class="caps">STROM</span>-<span class="caps">MM</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>Max the reward in their own Q-table</td>
<td>Finds equilibrium with one Q-table and determines both side&#8217;s <span class="math">\(a\)</span> at the same time</td>
</tr>
<tr>
<td>Pure Strategies</td>
<td>Mixed Strategies</td>
</tr>
<tr>
<td>Choose strategy by greedy</td>
<td>Samples from the mixed strategy <span class="math">\(\pi_a\)</span> or <span class="math">\(\pi_o\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li>Ideally, they should have simliar result in two-party <span class="caps">MRCIM</span>. In practice, the result might not due to<ul>
<li><span class="caps">STORM</span>-<span class="caps">QQ</span> does not guarantee&nbsp;equilibrium</li>
<li>Although equilibrium exists in <span class="caps">STORM</span>-<span class="caps">MM</span>. It does not guarantee to be found due to lack of training data or bad init or such&nbsp;problems.</li>
</ul>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </article>

        <div class="tags">
            <p>tags: <a href="http://lee-w.github.io/tag/social-network.html">Social Network</a>, <a href="http://lee-w.github.io/tag/machine-learning.html">Machine Learning</a>, <a href="http://lee-w.github.io/tag/game-theory.html">Game Theory</a></p>
        </div>

    <hr>


        <div class="comments">
            <h2>Comments !</h2>
            <div id="disqus_thread"></div>
            <script type="text/javascript">
                var disqus_shortname = 'lee-w-blog';
                var disqus_identifier = 'posts/paper-summary/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks';
                var disqus_url = 'http://lee-w.github.io/posts/paper-summary/2016/08/a-learning-based-framework-to-handle-multi-round-multi-party-inflence-maximization-on-social-networks';
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//lee-w-blog.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            </script>
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                            <li>
                                <a href="http://tw.linkedin.com/in/clleew">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="http://github.com/Lee-W">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="https://gitlab.com/Lee-W">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-gitlab fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="http://www.facebook.com/clleew">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li>
                                <a href="//lee-w.github.io/feeds/all.atom.xml">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                    </ul>
<p class="copyright text-muted">
    Blog powered by <a href="http://getpelican.com">Pelican</a>,
    which takes great advantage of <a href="http://python.org">Python</a>. <br />        &copy;  Lee-W
</p>                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="http://lee-w.github.io/theme/js/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="http://lee-w.github.io/theme/js/bootstrap.min.js"></script>

        <!-- Custom Theme JavaScript -->
        <script src="http://lee-w.github.io/theme/js/clean-blog.min.js"></script>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-96190677-1', 'auto');
    ga('send', 'pageview');
</script>
<script type="text/javascript">
    var disqus_shortname = 'lee-w-blog';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>

</html>